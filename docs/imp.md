ä»¥ä¸‹æä¾›ä¸€ä»½**ã€Œæ ¸å¿ƒæ¼”ç®—æ³•å¯¦ä½œå¼•å°ï¼ˆImplementation Guideï¼‰ã€**ï¼Œç›®æ¨™æ˜¯è®“ä½ å¯ä»¥**ä¾ç…§ CARROT ç†è«–ä¸€æ­¥æ­¥æŠŠæ ¸å¿ƒæ¨¡çµ„å¯«å®Œ**ï¼Œè€Œä¸è¢«å·¥ç¨‹ç´°ç¯€ç¶ä½ã€‚
æˆ‘æœƒ**åªèšç„¦ `carrot/` åº•ä¸‹çš„æ¨¡çµ„è¨­è¨ˆèˆ‡è²¬ä»»åŠƒåˆ†**ï¼Œ`main.py` åªç•¶ orchestrationã€‚

---

# ä¸€ã€æ•´é«”è³‡æ–™æµï¼ˆå…ˆå»ºç«‹å¿ƒæ™ºæ¨¡å‹ï¼‰

**å–®å¼µå½±åƒ forward flowï¼š**

```
image
  â†“ backbone (ViT)
patch tokens H, positions P
  â†“ region graph construction
graph (W, L)
  â†“ graph operator (diffusion)
H'
  â†“ readout
g (image embedding)
```

**æ•´å€‹ training / inference flowï¼š**

```
train images â†’ g_train â†’ closed-form head (solve W*)
test image   â†’ g_test  â†’ logits + exact attribution
```

---

# äºŒã€å»ºè­°æ¨¡çµ„åˆ‡åˆ†ï¼ˆå°é½Šä½ çš„è«–æ–‡æ•˜äº‹ï¼‰

```
carrot/
â”œâ”€â”€ backbone.py        # ViT wrapperï¼šåªè² è²¬æŠ½ patch tokens
â”œâ”€â”€ regions.py         # region / patch å®šç¾©èˆ‡åº§æ¨™
â”œâ”€â”€ graph.py           # graph construction (W, L)
â”œâ”€â”€ operator.py        # graph operator (diffusion)
â”œâ”€â”€ readout.py         # graph â†’ image embedding
â”œâ”€â”€ head.py            # closed-form ridge head + attribution
â”œâ”€â”€ attribution.py    # region-level / data-level attribution
â””â”€â”€ utils.py
```

ä¸‹é¢é€ä¸€èªª **ã€Œæ¯å€‹æ¨¡çµ„è¦åšä»€éº¼ã€ä¸åšä»€éº¼ã€**ã€‚

---

# ä¸‰ã€å„æ¨¡çµ„å¯¦ä½œå¼•å°ï¼ˆæ ¸å¿ƒï¼‰

å¯ä»¥ï¼Œç”¨ **timm** çš„è©±æˆ‘å»ºè­°æŠŠã€ŒæŠ½ patch tokensã€åšæˆä¸€å€‹**è¶…è–„ã€ä½†å¾ˆè€ç”¨**çš„ wrapperï¼š**æ°¸é åªä¾è³´ timm ViT ç³»åˆ—å…±åŒçš„å¹¾å€‹å±¬æ€§/è¡Œç‚º**ï¼ˆ`forward_features`ã€`num_prefix_tokens`ã€`patch_embed`ï¼‰ï¼Œé¿å…ä½ ä¹‹å¾Œæ› DeiT/BEiT/EVA ä¹‹é¡åˆè¦é‡å¯«ã€‚

ä¸‹é¢æˆ‘é‡æ–°å¯«ä¸€ä»½ã€Œtimm å…¼å®¹ç‰ˆã€çš„ backbone å¼•å° + ç›´æ¥å¯ç”¨çš„ skeletonï¼ˆä½ å°±æ”¾ `carrot/backbone.py`ï¼‰ã€‚

---

## è¨­è¨ˆç›®æ¨™ï¼ˆtimm å…¼å®¹ç‰ˆï¼‰

ä½ è¦çš„è¼¸å‡ºåªæœ‰å…©å€‹ï¼š

* `H`: **patch tokens**ï¼Œshape `(B, N, D)`ï¼ˆæŠŠ cls/dist token å»æ‰ï¼‰
* `P`: **patch center positions**ï¼Œshape `(N, 2)`ï¼ˆå›ºå®šå°æ‡‰åˆ°æ¯å€‹ patch çš„ä¸­å¿ƒåº§æ¨™ï¼‰

ä¸¦ä¸”è¦åšåˆ°ï¼š

1. **å…¼å®¹** timm çš„ ViT / DeiT / BEiT ç­‰ã€Œtoken-based transformerã€æ¨¡å‹
2. ä¸ä¾è³´æŸå€‹ç‰¹å®šå‹è™Ÿçš„ internal nameï¼ˆé¿å… fragile hookï¼‰
3. æ”¯æ´ä¸åŒ input sizeï¼ˆè‡³å°‘èƒ½å¾è¼¸å…¥æ¨ gridï¼‰

---

## `carrot/backbone.py`ï¼ˆå»ºè­°ç‰ˆæœ¬ï¼‰

```python
# carrot/backbone.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Tuple

import torch
import torch.nn as nn
import timm


@dataclass
class PatchOutput:
    H: torch.Tensor   # (B, N, D) patch tokens
    P: torch.Tensor   # (N, 2) patch centers (normalized)
    grid_hw: Tuple[int, int]  # (gh, gw)
    patch_hw: Tuple[int, int] # (ph, pw)


class TimmViTPatchBackbone(nn.Module):
    """
    A thin wrapper that extracts patch tokens from timm ViT-like models robustly.
    - returns patch tokens H (no cls/dist tokens)
    - returns patch centers P aligned with the patch order
    """
    def __init__(
        self,
        model_name: str,
        pretrained: bool = True,
        img_size: Optional[int] = None,
        freeze: bool = True,
        out_norm: bool = True,
        device: Optional[torch.device] = None,
    ):
        super().__init__()

        # timm create_model: num_classes=0 removes classifier head for many models
        self.model = timm.create_model(
            model_name,
            pretrained=pretrained,
            num_classes=0,
            img_size=img_size,          # some models accept it; safe to pass if you want fixed size
        )

        # Many timm ViT-like models expose these; we keep fallbacks
        self.out_norm = out_norm

        if freeze:
            self.model.eval()
            for p in self.model.parameters():
                p.requires_grad = False

        if device is not None:
            self.model.to(device)

    @torch.no_grad()
    def forward(self, x: torch.Tensor) -> PatchOutput:
        """
        x: (B, 3, H, W)
        """
        # 1) forward_features usually returns tokens (B, T, D) or a pooled vector depending on model.
        tokens = self._forward_tokens(x)  # (B, T, D)

        # 2) drop prefix tokens (cls/dist/others)
        patch_tokens = self._strip_prefix_tokens(tokens)  # (B, N, D)

        # 3) compute grid from input size & patch size
        gh, gw, ph, pw = self._infer_grid_and_patch(x, patch_tokens)

        # 4) optionally apply a normalization (some models already do this in forward_features)
        # We keep it optional to avoid double-normalizing.
        if self.out_norm and hasattr(self.model, "norm") and isinstance(self.model.norm, nn.Module):
            patch_tokens = self.model.norm(patch_tokens)

        # 5) patch centers positions (N, 2), normalized to [-1, 1]
        P = self._make_patch_centers(gh, gw, device=patch_tokens.device, dtype=patch_tokens.dtype)

        return PatchOutput(
            H=patch_tokens,
            P=P,
            grid_hw=(gh, gw),
            patch_hw=(ph, pw),
        )

    def _forward_tokens(self, x: torch.Tensor) -> torch.Tensor:
        """
        Try best-effort methods to get token sequence from timm models.
        """
        # Most ViT-like models in timm implement forward_features(x) -> (B, T, D)
        if hasattr(self.model, "forward_features"):
            y = self.model.forward_features(x)
        else:
            # fallback to forward; may return pooled vector; we try to avoid this
            y = self.model(x)

        # Some models might return a tuple/list; take first tensor that looks like tokens
        if isinstance(y, (tuple, list)):
            for t in y:
                if torch.is_tensor(t) and t.dim() == 3:
                    return t
            raise RuntimeError("Cannot find token tensor (B, T, D) in model output tuple/list.")

        if torch.is_tensor(y) and y.dim() == 3:
            return y

        raise RuntimeError(
            "Model did not return tokens (B, T, D). "
            "Try a different timm model (ViT/DeiT/BEiT-style token models)."
        )

    def _strip_prefix_tokens(self, tokens: torch.Tensor) -> torch.Tensor:
        """
        Remove prefix tokens like CLS/DIST.
        timm ViT-like models often expose num_prefix_tokens.
        """
        n_prefix = None

        # timm VisionTransformer / DeiT commonly has num_prefix_tokens
        if hasattr(self.model, "num_prefix_tokens"):
            n_prefix = int(getattr(self.model, "num_prefix_tokens"))

        # fallback heuristics
        if n_prefix is None:
            # many ViT have cls_token attribute
            n_prefix = 1 if hasattr(self.model, "cls_token") else 0
            # DeiT dist token
            if hasattr(self.model, "dist_token"):
                n_prefix += 1

        if n_prefix == 0:
            return tokens

        if tokens.size(1) <= n_prefix:
            raise RuntimeError(f"Token length {tokens.size(1)} <= prefix tokens {n_prefix}.")

        return tokens[:, n_prefix:, :]

    def _infer_grid_and_patch(
        self, x: torch.Tensor, patch_tokens: torch.Tensor
    ) -> Tuple[int, int, int, int]:
        """
        Infer patch grid (gh, gw) and patch size (ph, pw).
        """
        B, _, H, W = x.shape
        N = patch_tokens.size(1)

        ph = pw = None
        if hasattr(self.model, "patch_embed") and hasattr(self.model.patch_embed, "patch_size"):
            ps = self.model.patch_embed.patch_size
            # patch_size could be int or tuple
            if isinstance(ps, tuple):
                ph, pw = int(ps[0]), int(ps[1])
            else:
                ph = pw = int(ps)

        # Prefer explicit grid_size if available
        gh = gw = None
        if hasattr(self.model, "patch_embed") and hasattr(self.model.patch_embed, "grid_size"):
            gs = self.model.patch_embed.grid_size
            if isinstance(gs, tuple):
                gh, gw = int(gs[0]), int(gs[1])

        # If grid_size missing or doesn't match N, derive from input size (more robust for dynamic resize)
        if ph is not None and pw is not None:
            gh2, gw2 = H // ph, W // pw
            if gh2 * gw2 == N:
                return gh2, gw2, ph, pw

        # last resort: assume square grid
        s = int(N ** 0.5)
        if s * s != N:
            raise RuntimeError(
                f"Cannot infer grid: N={N} not a perfect square, and input-derived grid failed. "
                f"Try ensuring input size divisible by patch size, or use a model exposing patch_embed.grid_size."
            )
        return s, s, (ph or -1), (pw or -1)

    def _make_patch_centers(
        self, gh: int, gw: int, device: torch.device, dtype: torch.dtype
    ) -> torch.Tensor:
        """
        Create patch centers aligned with token order:
        Typically row-major order: (y=0,x=0..gw-1), (y=1, ...)
        Output normalized to [-1, 1] in both axes.
        """
        ys = (torch.arange(gh, device=device, dtype=dtype) + 0.5) / gh  # (gh,)
        xs = (torch.arange(gw, device=device, dtype=dtype) + 0.5) / gw  # (gw,)

        # meshgrid: y first then x to match row-major flatten
        yy, xx = torch.meshgrid(ys, xs, indexing="ij")  # (gh, gw)
        P = torch.stack([xx.reshape(-1), yy.reshape(-1)], dim=-1)  # (N, 2), in [0,1]

        # map [0,1] -> [-1,1]
        P = P * 2.0 - 1.0
        return P
```

---

## ä½¿ç”¨æ–¹å¼ï¼ˆä½ åœ¨ `main.py` è£¡é¢ï¼‰

ä½ åªè¦æŠŠå®ƒç•¶ä¸€å€‹ã€Œpatch token ä¾›æ‡‰å™¨ã€ï¼š

```python
backbone = TimmViTPatchBackbone("vit_base_patch16_224", pretrained=True, freeze=True)

out = backbone(images)   # images: (B,3,H,W)
H = out.H                # (B,N,D)
P = out.P                # (N,2)
```

---

## é€™å€‹ç‰ˆæœ¬æ¯”ã€Œç›´æ¥ç¡¬æŠ“æŸå±¤ã€æ›´å…¼å®¹çš„åŸå› 

* **ä¸é  hook**ï¼šhook å°ä¸åŒ timm model æœƒè¶…è„†ï¼ˆå±¤å/çµæ§‹å¸¸è®Šï¼‰
* **ç”¨ `num_prefix_tokens`**ï¼šé€™æ˜¯ timm åœ¨ ViT/DeiT ç³»åˆ—å¾ˆä¸€è‡´çš„æŠ½è±¡ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å† heuristicï¼‰
* **grid æ¨å°å„ªå…ˆç”¨è¼¸å…¥**ï¼šä½ å¯¦é©— FGVC å¸¸æœƒåš resize/cropï¼Œä¸ä¸€å®šæ°¸é æ˜¯ 224ï¼›ç”¨è¼¸å…¥åæ¨æ›´ç©©

---

## å…©å€‹ä½ å¾ˆå¯èƒ½æœƒè¸©çš„å‘ï¼ˆæˆ‘å…ˆå¹«ä½ é¿æ‰ï¼‰

1. **`forward_features` æœ‰äº›æ¨¡å‹å›å‚³ä¸æ˜¯ tokens**
   ä¸Šé¢æˆ‘å·²ç¶“åšäº†æª¢æŸ¥ï¼šä¸æ˜¯ `(B,T,D)` å°±ç›´æ¥å ±éŒ¯ï¼Œé€¼ä½ æ›å°çš„æ¨¡å‹ï¼ˆæˆ–æ”¹ extraction è·¯å¾‘ï¼‰ã€‚

2. **è¼¸å…¥å°ºå¯¸è¦èƒ½è¢« patch size æ•´é™¤**
   ä¸ç„¶ `H//ph`ã€`W//pw` æœƒå°ä¸ä¸Š `N`ï¼Œæˆ‘ä¹Ÿç›´æ¥è®“å®ƒå ±éŒ¯ï¼Œé¿å…ä½ å¾Œé¢å»ºåœ–éœé»˜éŒ¯é…ã€‚

---

## 2ï¸âƒ£ `regions.py` â€” Region å®šç¾©ï¼ˆå…¶å¯¦å¾ˆè–„ï¼‰

**è²¬ä»»ï¼š**

* å°è£ã€Œä»€éº¼æ˜¯ä¸€å€‹ regionã€
* optionalï¼špatch coarseningï¼ˆå¯å…ˆä¸å¯¦ä½œï¼‰

```python
@dataclass
class RegionSet:
    features: Tensor  # H
    positions: Tensor # P
```

> é€™ä¸€å±¤å¹¾ä¹æ˜¯èªæ„å±¤ï¼Œä¸æ˜¯æ•¸å­¸å±¤
> å¥½è™•æ˜¯ä¹‹å¾Œæ› backbone / pooling ä¸æœƒå‹•å¾Œé¢æ¨¡çµ„

---

## 3ï¸âƒ£ `graph.py` â€” CARROT Graph Constructionï¼ˆé—œéµï¼‰

**è²¬ä»»ï¼š**

* æ ¹æ“š `(H, P)` å»ºæ§‹ **åŠ æ¬Š adjacency matrix `W`**
* å›å‚³ **graph Laplacian `L`**

### æ ¸å¿ƒ API

```python
class RegionGraphBuilder:
    def build(self, regions: RegionSet):
        """
        return:
            W: (N, N) weighted adjacency
            L: (N, N) normalized Laplacian
        """
```

### å¯¦ä½œé †åºå»ºè­°

1. **pairwise spatial distance**
2. **pairwise feature distance**
3. å„è‡ªå¥— Gaussian kernel
4. element-wise ç›¸ä¹˜ â†’ `W`
5. æ­£è¦åŒ– â†’ `L = I - D^{-1/2} W D^{-1/2}`

> âš ï¸ é‡é»ï¼š
>
> * ä¸è¦ KNNã€ä¸è¦ thresholdï¼ˆå…ˆåšå®Œæ•´åœ–ï¼‰
> * å¯å…ˆç”¨ `torch.cdist`ï¼Œå†å„ªåŒ–

---

## 4ï¸âƒ£ `operator.py` â€” Graph Operatorï¼ˆç†è«–æ ¸å¿ƒï¼‰

**è²¬ä»»ï¼š**

* å¯¦ä½œã€Œå¯åˆ†æã€çš„åœ–ç®—å­
* **ä¸å¼•å…¥ learnable parameters**

### Diffusion operator

```python
class DiffusionOperator:
    def __init__(self, t: float):
        self.t = t

    def forward(self, H, L):
        """
        H': exp(-t L) @ H
        """
```

### å¯¦ä½œé¸é …ï¼ˆç…§ä½ è«–æ–‡ï¼‰

* å° Nï¼š`torch.matrix_exp(-t * L)`
* å¤§ Nï¼štruncated eigendecompositionï¼ˆå¯å¾ŒçºŒï¼‰

**é€™ä¸€å±¤æ˜¯ CARROT çš„ç†è«–éˆé­‚ï¼Œä¸è¦æ··å…¥ GNNã€‚**

---

## 5ï¸âƒ£ `readout.py` â€” Graph â†’ Image Embedding

**è²¬ä»»ï¼š**

* æŠŠ node-level è¡¨å¾µè®Šæˆ image-level `g`

```python
class GraphReadout:
    def forward(self, H_prime):
        """
        return:
            g: (d,)
        """
```

* æœ€ä¹¾æ·¨ï¼š`mean pooling`
* å¥½è™•ï¼šclosed-form head æ¨å°æœ€ä¹¾æ·¨

---

## 6ï¸âƒ£ `head.py` â€” Closed-form Classification Headï¼ˆå¦ä¸€å€‹éˆé­‚ï¼‰

**è²¬ä»»ï¼š**

* **ä¸æ˜¯ nn.Module**
* å„²å­˜ training embeddings
* è§£ ridge regression çš„é–‰å¼è§£
* æä¾› logit èˆ‡ attribution æ‰€éœ€é‡

```python
class RidgeHead:
    def fit(self, G_train, Y_train):
        """
        solve W* = (G^T G + Î»I)^(-1) G^T Y
        """

    def predict(self, g_test):
        """
        return logits
        """
```

> âš ï¸ é‡é»ï¼š
>
> * é€™è£¡æ˜¯ **exact training-data attribution èƒ½æˆç«‹çš„é—œéµ**
> * ä¸è¦ç”¨ SGDã€ä¸ç”¨ torch optimizer

---

## 7ï¸âƒ£ `attribution.py` â€” è§£é‡‹èˆ‡æ­¸å› ï¼ˆç¨ç«‹æ–¼æ¨¡å‹ï¼‰

**è²¬ä»»ï¼š**

* åˆ©ç”¨ `head` çš„é–‰å¼æ€§è³ª
* åˆ†æï¼š

  * training sample contribution
  * region / subgraph contribution

### Training-data attribution

```python
def training_contribution(g_test, G_train, alpha):
    """
    return: contribution per training sample
    """
```

### Region attributionï¼ˆå–®å¼µåœ–ï¼‰

* åŸºæ–¼ï¼š

  * node energy contribution
  * remove-node â†’ logit drop
* **ä¸éœ€è¦ gradient**

> é€™å±¤å®Œå…¨æ˜¯ã€Œåˆ†æå·¥å…·ã€ï¼Œä¸è¦æ··é€² forward

---

# å››ã€`main.py` æ‡‰è©²é•·æ€æ¨£ï¼ˆå¿ƒæ³•ï¼‰

`main.py` åªåšä¸‰ä»¶äº‹ï¼š

1. **ä¸² pipeline**
2. **å­˜ä¸­é–“é‡ï¼ˆH, W, gï¼‰ä¾›åˆ†æ**
3. **è·‘ evaluation protocol**

```python
# pseudo
H, P = backbone(x)
regions = RegionSet(H, P)
W, L = graph_builder.build(regions)
H_ = operator(H, L)
g = readout(H_)
```

> å¦‚æœ `main.py` è¶…é 200 è¡Œï¼Œä»£è¡¨æ¨¡çµ„åˆ‡å¾—ä¸å¤ ä¹¾æ·¨

---

# äº”ã€å¯¦ä½œé †åºå»ºè­°ï¼ˆå‹™å¯¦ï¼‰

1. `backbone â†’ regions`
2. `graph.py`ï¼ˆå…ˆç¢ºèª W åˆç†ï¼‰
3. `operator.py`ï¼ˆçœ‹ smoothing effectï¼‰
4. `readout`
5. `head.fit / predict`
6. `attribution.py`

ğŸ‘‰ **å…ˆè·‘é€šä¸€å¼µ image + toy datasetï¼Œå†è«‡ CUB / FGVC**

---

# å…­ã€ä¸€å¥å·¥ç¨‹å°å‘ç¸½çµ

> **CARROT çš„å¯¦ä½œä¸æ˜¯åœ¨ã€Œå †æ¨¡å‹ã€ï¼Œ
> è€Œæ˜¯åœ¨æŠŠæ¯ä¸€å€‹æ•¸å­¸ç‰©ä»¶ï¼ˆH, W, L, g, W*ï¼‰
> éƒ½è®Šæˆä¸€å€‹å¯å–®ç¨æª¢æŸ¥ã€å¯ç†è«–å°æ‡‰çš„æ¨¡çµ„ã€‚**

å¦‚æœä½ é¡˜æ„ï¼Œä¸‹ä¸€æ­¥æˆ‘å¯ä»¥å¹«ä½ åšï¼š

* ğŸ”¹ **`graph.py` çš„æ•¸å­¸å°æ‡‰ â†’ ç¨‹å¼ skeleton**
* ğŸ”¹ **`head.py` çš„ attribution å…¬å¼ â†’ å¯ç›´æ¥è·‘çš„ code**
* ğŸ”¹ **ä¸€å€‹ã€Œæœ€å°å¯é©—è­‰ CARROTã€toy example**
